{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 避开抓取陷阱\n",
    "\n",
    "\n",
    "\n",
    "1. 修改请求头   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PageElement.get_text of <table class=\"table table-striped table-data\">\n",
      "<tr>\n",
      "<th>Accept</th>\n",
      "<td>text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>Accept-Encoding</th>\n",
      "<td>gzip, deflate</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>Connection</th>\n",
      "<td>keep-alive</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>Content-Length</th>\n",
      "<td></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>Content-Type</th>\n",
      "<td></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>Host</th>\n",
      "<td>www.whatismybrowser.com</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>User-Agent</th>\n",
      "<td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5)AppleWebKit 537.36 (KHTML, like Gecko) Chrome</td>\n",
      "</tr>\n",
      "</table>>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "session = requests.Session()\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5)'\n",
    "                'AppleWebKit 537.36 (KHTML, like Gecko) Chrome',\n",
    "                'Accept':'text/html,application/xhtml+xml,application/xml;'\n",
    "                'q=0.9,image/webp,*/*;q=0.8'}\n",
    "url = 'https://www.whatismybrowser.com/detect/what-http-headers-is-my-browser-sending'\n",
    "req = session.get(url, headers=headers)\n",
    "bs = BeautifulSoup(req.text, 'html.parser')\n",
    "print(bs.find('table', {'class':'table-striped'}).get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 用JavaScript处理cookie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome( executable_path='/Users/danyow/chromedriver')\n",
    "driver.get('http://pythonscraping.com')\n",
    "driver.implicitly_wait(1)\n",
    "print(driver.get_cookies())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你还可以调用 delete_cookie()、add_cookie() 和 delete_all_cookies() 方法来处理 cookie。 另外，还可以保存 cookie 以备其他网络爬虫使用。下面的例子演示了如何把这些函数组合 在一起:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "phantomPath = \"/Users/danyow/chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=  phantomPath)\n",
    "driver.get('http://pythonscraping.com')\n",
    "driver.implicitly_wait(1)\n",
    "\n",
    "savedCookie = driver.get_cookies()\n",
    "savedCookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "driver2 = webdriver.Chrome(executable_path=  phantomPath)\n",
    "driver2.get('http://pythonscraping.com')\n",
    "driver2.delete_all_cookies()\n",
    "for cookie in savedCookie:\n",
    "    if not cookie['domain'].startswith('.'):\n",
    "        cookie['domain'] = '.{}'.format(cookie['domain'])\n",
    "        driver2.add_cookie(cookie)\n",
    "driver2.get('http://pythonscraping.com')\n",
    "driver2.implicitly_wait(1)\n",
    "print(driver2.get_cookies())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 等待时间继续爬取\n",
    "\n",
    "\n",
    "\n",
    "虽然多线程程序可能是一个快速加载页面的好办法——让你在一个线程中处理数据 并在另一个线程中加载页面——但是这对编写好的爬虫来说依然是一种糟糕的策略。应该 尽量保证页面加载和数据请求最小化。如果可能，尽量在页面访问之间增加几秒钟的间 隔，即使你需要增加一行代码:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取网页上隐藏css的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The link http://pythonscraping.com/dontgohere is a trap\n",
      "Do not change value of phone\n",
      "Do not change value of email\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "phantomPath = \"/Users/danyow/chromedriver\"\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=phantomPath,\n",
    "    )\n",
    "driver.get('http://pythonscraping.com/pages/itsatrap.html')\n",
    "links = driver.find_elements_by_tag_name('a')\n",
    "for link in links:\n",
    "    if not link.is_displayed():\n",
    "        print('The link {} is a trap'.format(link.get_attribute('href')))\n",
    "\n",
    "fields = driver.find_elements_by_tag_name('input')\n",
    "for field in fields:\n",
    "    if not field.is_displayed():\n",
    "        print('Do not change value of {}'.format(field.get_attribute('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('myenvs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a051216bf3a65c020b643b52ab15d0714db61718a99958c54a11e422694469a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
